<!-- Generated by documentation.js. Update this documentation by updating the source code. -->

### Table of Contents

-   [constructor][1]
    -   [Parameters][2]
-   [model][3]
-   [audioContext][4]
-   [stream][5]
-   [results][6]
-   [getPitch][7]
    -   [Parameters][8]
-   [centMapping][9]
-   [constructor][10]
    -   [Parameters][11]
-   [loadModel][12]
    -   [Parameters][13]
-   [classifyInternal][14]
    -   [Parameters][15]
-   [classify][16]
    -   [Parameters][17]
-   [predict][18]
    -   [Parameters][19]
-   [constructor][20]
    -   [Parameters][21]
-   [classify][22]
    -   [Parameters][23]
-   [constructor][24]
-   [addExample][25]
    -   [Parameters][26]
-   [classify][27]
    -   [Parameters][28]
-   [clearLabel][29]
    -   [Parameters][30]
-   [getCountByLabel][31]
-   [getCount][32]
-   [getNumLabels][33]
-   [save][34]
    -   [Parameters][35]
-   [load][36]
    -   [Parameters][37]
-   [options][38]
    -   [Properties][39]
-   [options][40]
    -   [Properties][41]
-   [options][42]
    -   [Properties][43]
-   [options][44]
    -   [Properties][45]
-   [options][46]
    -   [Properties][47]
-   [featureExtractor][48]
    -   [Parameters][49]
-   [hasAnyTrainedClass][50]
-   [isPredicting][51]
-   [usageType][52]
-   [classification][53]
    -   [Parameters][54]
-   [regression][55]
    -   [Parameters][56]
-   [addImage][57]
    -   [Parameters][58]
-   [train][59]
    -   [Parameters][60]
-   [classify][61]
    -   [Parameters][62]
-   [predict][63]
    -   [Parameters][64]
-   [constructor][65]
    -   [Parameters][66]
-   [constructor][67]
    -   [Parameters][68]
-   [constructor][69]
    -   [Parameters][70]
-   [detect][71]
    -   [Parameters][72]
-   [detectInternal][73]
    -   [Parameters][74]
-   [ObjectDetectorPrediction][75]
    -   [Properties][76]
-   [ObjectDetectorPrediction][77]
    -   [Properties][78]
-   [ObjectDetectorPredictionNormalized][79]
    -   [Properties][80]
-   [ObjectDetectorPredictionNormalized][81]
    -   [Properties][82]
-   [constructor][83]
    -   [Parameters][84]
-   [constructor][85]
    -   [Parameters][86]
-   [loadModel][87]
-   [detectInternal][88]
    -   [Parameters][89]
-   [detect][90]
    -   [Parameters][91]
-   [constructor][92]
    -   [Parameters][93]
-   [modelUrl][94]
-   [singlePose][95]
    -   [Parameters][96]
-   [multiPose][97]
    -   [Parameters][98]
-   [constructor][99]
    -   [Parameters][100]
-   [ready][101]
-   [transfer][102]
    -   [Parameters][103]
-   [constructor][104]
    -   [Parameters][105]
-   [ready][106]
-   [model][107]
-   [state][108]
-   [reset][109]
-   [generate][110]
    -   [Parameters][111]
-   [predict][112]
    -   [Parameters][113]
-   [feed][114]
    -   [Parameters][115]
-   [constructor][116]
    -   [Parameters][117]
-   [ready][118]
-   [transfer][119]
    -   [Parameters][120]
-   [constructor][121]
    -   [Parameters][122]
-   [constructor][123]
    -   [Parameters][124]
-   [constructor][125]
    -   [Parameters][126]
-   [ready][127]
-   [generate][128]
    -   [Parameters][129]
-   [constructor][130]
    -   [Parameters][131]
-   [loadModel][132]
-   [generate][133]
    -   [Parameters][134]
-   [compute][135]
    -   [Parameters][136]
-   [generateInternal][137]
    -   [Parameters][138]
-   [registerPreload][139]
    -   [Parameters][140]
-   [OOV_CHAR][141]
-   [constructor][142]
    -   [Parameters][143]
-   [ready][144]
-   [loadModel][145]
    -   [Parameters][146]
-   [model][147]
-   [predict][148]
    -   [Parameters][149]
-   [constructor][150]
    -   [Parameters][151]
-   [loadModel][152]
-   [p5Color2RGB][153]
    -   [Parameters][154]
-   [convertToP5Image][155]
    -   [Parameters][156]
-   [bodyPartsSpec][157]
    -   [Parameters][158]
-   [segmentWithPartsInternal][159]
    -   [Parameters][160]
-   [segmentWithParts][161]
    -   [Parameters][162]
-   [segmentInternal][163]
    -   [Parameters][164]
-   [segment][165]
    -   [Parameters][166]
-   [init][167]
    -   [Parameters][168]
-   [init][169]
    -   [Parameters][170]
-   [createLayersNoTraining][171]
-   [copy][172]
-   [addData][173]
    -   [Parameters][174]
-   [addData][175]
    -   [Parameters][176]
-   [loadDataFromUrl][177]
    -   [Parameters][178]
-   [loadDataInternal][179]
    -   [Parameters][180]
-   [createMetaData][181]
    -   [Parameters][182]
-   [prepareForTraining][183]
    -   [Parameters][184]
-   [prepareForTraining][185]
    -   [Parameters][186]
-   [normalizeData][187]
    -   [Parameters][188]
-   [normalizeInput][189]
    -   [Parameters][190]
-   [searchAndFormat][191]
    -   [Parameters][192]
-   [formatInputItem][193]
    -   [Parameters][194]
-   [convertTrainingDataToTensors][195]
    -   [Parameters][196]
-   [formatInputsForPrediction][197]
    -   [Parameters][198]
-   [formatInputsForPredictionAll][199]
    -   [Parameters][200]
-   [isOneHotEncodedOrNormalized][201]
    -   [Parameters][202]
-   [train][203]
    -   [Parameters][204]
-   [train][205]
    -   [Parameters][206]
-   [trainInternal][207]
    -   [Parameters][208]
-   [addLayer][209]
    -   [Parameters][210]
-   [createNetworkLayers][211]
    -   [Parameters][212]
-   [addDefaultLayers][213]
    -   [Parameters][214]
-   [compile][215]
    -   [Parameters][216]
-   [predictSync][217]
    -   [Parameters][218]
-   [predictSync][219]
    -   [Parameters][220]
-   [predict][221]
    -   [Parameters][222]
-   [predictMultiple][223]
    -   [Parameters][224]
-   [classifySync][225]
    -   [Parameters][226]
-   [classify][227]
    -   [Parameters][228]
-   [classifyMultiple][229]
    -   [Parameters][230]
-   [predictSyncInternal][231]
    -   [Parameters][232]
-   [predictInternal][233]
    -   [Parameters][234]
-   [classifySyncInternal][235]
    -   [Parameters][236]
-   [classifyInternal][237]
    -   [Parameters][238]
-   [saveData][239]
    -   [Parameters][240]
-   [saveData][241]
    -   [Parameters][242]
-   [loadData][243]
    -   [Parameters][244]
-   [save][245]
    -   [Parameters][246]
-   [save][247]
    -   [Parameters][248]
-   [load][249]
    -   [Parameters][250]
-   [dispose][251]
-   [mutate][252]
    -   [Parameters][253]
-   [mutate][254]
    -   [Parameters][255]
-   [crossover][256]
    -   [Parameters][257]
-   [init][258]
-   [createModel][259]
    -   [Parameters][260]
-   [addLayer][261]
    -   [Parameters][262]
-   [compile][263]
    -   [Parameters][264]
-   [setOptimizerFunction][265]
    -   [Parameters][266]
-   [train][267]
    -   [Parameters][268]
-   [trainInternal][269]
    -   [Parameters][270]
-   [predictSync][271]
    -   [Parameters][272]
-   [predict][273]
    -   [Parameters][274]
-   [classify][275]
    -   [Parameters][276]
-   [classifySync][277]
    -   [Parameters][278]
-   [save][279]
    -   [Parameters][280]
-   [load][281]
    -   [Parameters][282]
-   [dispose][283]
-   [mutate][284]
    -   [Parameters][285]
-   [crossover][286]
    -   [Parameters][287]
-   [createMetadata][288]
    -   [Parameters][289]
-   [createMetadata][290]
    -   [Parameters][291]
-   [getDataStats][292]
    -   [Parameters][293]
-   [getInputMetaStats][294]
    -   [Parameters][295]
-   [getDataUnits][296]
    -   [Parameters][297]
-   [getInputMetaUnits][298]
    -   [Parameters][299]
-   [getDTypesFromData][300]
    -   [Parameters][301]
-   [addData][302]
    -   [Parameters][303]
-   [addData][304]
    -   [Parameters][305]
-   [convertRawToTensors][306]
    -   [Parameters][307]
-   [convertRawToTensors][308]
    -   [Parameters][309]
-   [normalizeDataRaw][310]
    -   [Parameters][311]
-   [normalizeDataRaw][312]
    -   [Parameters][313]
-   [normalizeInputData][314]
    -   [Parameters][315]
-   [normalizeArray][316]
    -   [Parameters][317]
-   [unnormalizeArray][318]
    -   [Parameters][319]
-   [applyOneHotEncodingsToDataRaw][320]
    -   [Parameters][321]
-   [getDataOneHot][322]
    -   [Parameters][323]
-   [getInputMetaOneHot][324]
    -   [Parameters][325]
-   [createOneHotEncodings][326]
    -   [Parameters][327]
-   [loadDataFromUrl][328]
    -   [Parameters][329]
-   [loadDataFromUrl][330]
    -   [Parameters][331]
-   [loadJSON][332]
    -   [Parameters][333]
-   [loadCSV][334]
    -   [Parameters][335]
-   [loadBlob][336]
    -   [Parameters][337]
-   [loadData][338]
    -   [Parameters][339]
-   [saveData][340]
    -   [Parameters][341]
-   [saveMeta][342]
    -   [Parameters][343]
-   [loadMeta][344]
    -   [Parameters][345]
-   [formatRawData][346]
    -   [Parameters][347]
-   [csvToJSON][348]
    -   [Parameters][349]
-   [findEntries][350]
    -   [Parameters][351]
-   [scatterplot][352]
    -   [Parameters][353]
-   [scatterplotAll][354]
    -   [Parameters][355]
-   [barchart][356]
    -   [Parameters][357]
-   [trainingVis][358]
    -   [Parameters][359]
-   [trainingVis][360]
-   [normalizeValue][361]
    -   [Parameters][362]
-   [unnormalizeValue][363]
    -   [Parameters][364]
-   [getMin][365]
    -   [Parameters][366]
-   [getMax][367]
    -   [Parameters][368]
-   [isJsonOrString][369]
    -   [Parameters][370]
-   [zipArrays][371]
    -   [Parameters][372]
-   [createLabelsFromArrayValues][373]
    -   [Parameters][374]
-   [formatDataAsObject][375]
    -   [Parameters][376]
-   [getDataType][377]
    -   [Parameters][378]
-   [constructor][379]
    -   [Parameters][380]
-   [loadModel][381]
-   [detect][382]
    -   [Parameters][383]
-   [detectInternal][384]
    -   [Parameters][385]
-   [detectSingle][386]
    -   [Parameters][387]
-   [detectSingleInternal][388]
    -   [Parameters][389]
-   [checkUndefined][390]
    -   [Parameters][391]
-   [getModelPath][392]
    -   [Parameters][393]
-   [setReturnOptions][394]
    -   [Parameters][395]
-   [resizeResults][396]
    -   [Parameters][397]
-   [landmarkParts][398]
    -   [Parameters][399]
-   [readCsv][400]
    -   [Parameters][401]
-   [loadDataset][402]
    -   [Parameters][403]
-   [constructor][404]
    -   [Parameters][405]
-   [load][406]
    -   [Parameters][407]
-   [fit][408]
-   [getClosestCentroids][409]
-   [closestCentroid][410]
    -   [Parameters][411]
-   [classify][412]
    -   [Parameters][413]
-   [recenterCentroids][414]
-   [getEuclidianDistance][415]
    -   [Parameters][416]
-   [constructor][417]
    -   [Parameters][418]
-   [generate][419]
    -   [Parameters][420]
-   [loadModel][421]
-   [predict][422]
    -   [Parameters][423]
-   [encode][424]
    -   [Parameters][425]
-   [setP5Instance][426]
    -   [Parameters][427]
-   [checkP5][428]
-   [getBlob][429]
    -   [Parameters][430]
-   [loadAsync][431]
    -   [Parameters][432]
-   [rawToBlob][433]
    -   [Parameters][434]
-   [blobToP5Image][435]
    -   [Parameters][436]

## constructor

Create a pitchDetection.

### Parameters

-   `model` **[Object][437]** The path to the trained model. Only CREPE is available for now. Case insensitive.
-   `audioContext` **AudioContext** The browser audioContext to use.
-   `stream` **MediaStream** The media stream to use.
-   `callback` **[function][438]** Optional. A callback to be called once the model has loaded. If no callback is provided, it will return a promise that will be resolved once the model has loaded.

## model

The pitch detection model.

Type: model

## audioContext

The AudioContext instance. Contains sampleRate, currentTime, state, baseLatency.

Type: AudioContext

## stream

The MediaStream instance. Contains an id and a boolean active value.

Type: MediaStream

## results

The current pitch prediction results from the classification model.

Type: [Object][437]

## getPitch

Returns the pitch from the model attempting to predict the pitch.

### Parameters

-   `callback` **[function][438]** Optional. A function to be called when the model has generated content. If no callback is provided, it will return a promise that will be resolved once the model has predicted the pitch.

Returns **[number][439]** 

## centMapping

A boolean value stating whether the model instance is running or not.

Type: [boolean][440]

## constructor

Create an ImageClassifier.

### Parameters

-   `modelNameOrUrl` **[string][441]** The name or the URL of the model to use. Current model name options
       are: 'mobilenet', 'darknet', 'darknet-tiny', and 'doodlenet'.
-   `video` **[HTMLVideoElement][442]** An HTMLVideoElement.
-   `options` **[object][437]** An object with options.
-   `callback` **[function][438]** A callback to be called when the model is ready.

## loadModel

Load the model and set it to this.model

### Parameters

-   `modelUrl`  

Returns **this** The ImageClassifier.

## classifyInternal

Classifies the given input and returns an object with labels and confidence

### Parameters

-   `imgToPredict` **([HTMLImageElement][443] \| [HTMLCanvasElement][444] \| [HTMLVideoElement][442])**    takes an image to run the classification on.
-   `numberOfClasses` **[number][439]** a number of labels to return for the image
       classification.

Returns **[object][437]** an object with {label, confidence}.

## classify

Classifies the given input and takes a callback to handle the results

### Parameters

-   `inputNumOrCallback` **([HTMLImageElement][443] \| [HTMLCanvasElement][444] \| [object][437] \| [function][438] \| [number][439])**    takes any of the following params
-   `numOrCallback` **([HTMLImageElement][443] \| [HTMLCanvasElement][444] \| [object][437] \| [function][438] \| [number][439])**    takes any of the following params (optional, default `null`)
-   `cb` **[function][438]** a callback function that handles the results of the function.

Returns **[function][438]** a promise or the results of a given callback, cb.

## predict

Will be deprecated soon in favor of ".classify()" - does the same as .classify()

### Parameters

-   `inputNumOrCallback` **([HTMLImageElement][443] \| [HTMLCanvasElement][444] \| [object][437] \| [function][438] \| [number][439])** takes any of the following params
-   `numOrCallback` **([HTMLImageElement][443] \| [HTMLCanvasElement][444] \| [object][437] \| [function][438] \| [number][439])** takes any of the following params
-   `cb` **[function][438]** a callback function that handles the results of the function.

Returns **[function][438]** a promise or the results of a given callback, cb.

## constructor

Create an SoundClassifier.

### Parameters

-   `modelNameOrUrl` **modelNameOrUrl** The name or the URL of the model to use. Current name options
       are: 'SpeechCommands18w'.
-   `options` **[object][437]** An object with options.
-   `callback` **[function][438]** A callback to be called when the model is ready.

## classify

Classifies the audio from microphone and takes a callback to handle the results

### Parameters

-   `numOrCallback` **([function][438] \| [number][439])**    takes any of the following params (optional, default `null`)
-   `cb` **[function][438]** a callback function that handles the results of the function.

Returns **[function][438]** a promise or the results of a given callback, cb.

## constructor

Create a KNNClassifier instance.

## addExample

Adding an example to a class.

### Parameters

-   `input` **any** An example to add to the dataset, usually an activation from another model.
-   `classIndexOrLabel`  

## classify

Classify an new input. It returns an object with a top classIndex and label, confidences mapping all class indices to their confidence, and confidencesByLabel mapping all classes' confidence by label.

### Parameters

-   `input` **any** An example to make a prediction on, could be an activation from another model or an array of numbers.
-   `kOrCallback`  
-   `cb`  
-   `k` **[number][439]** Optional. The K value to use in K-nearest neighbors. The algorithm will first find the K nearest examples from those it was previously shown, and then choose the class that appears the most as the final prediction for the input example. Defaults to 3. If examples &lt; k, k = examples.
-   `callback` **[function][438]** Optional. A function to be called once the input has been classified. If no callback is provided, it will return a promise that will be resolved once the model has classified the new input.

## clearLabel

Clear all examples in a label.

### Parameters

-   `labelIndex`  

## getCountByLabel

Get the example count for each label. It returns an object that maps class label to example count for each class.

Returns **[Number][439]** 

## getCount

Get the example count for each class. It returns an object that maps class index to example count for each class.

Returns **[Number][439]** 

## getNumLabels

It returns the total number of labels.

Returns **[String][441]** 

## save

Download the whole dataset as a JSON file. It's useful for saving state.

### Parameters

-   `name` **[String][441]** Optional. The name of the JSON file that will be downloaded. e.g. "myKNN" or "myKNN.json". If no fileName is provided, the default file name is "myKNN.json".

## load

Load a dataset from a JSON file. It's useful for restoring state.

### Parameters

-   `pathOrData` **[String][441]** The path for a valid JSON file.
-   `callback` **[function][438]** Optional. A function to run once the dataset has been loaded. If no callback is provided, it will return a promise that will be resolved once the dataset has loaded.

## options

Type: [Object][437]

### Properties

-   `version` **[number][439]** default 1
-   `alpha` **[number][439]** default 1.0
-   `topk` **[number][439]** default 3
-   `learningRate` **[number][439]** default 0.0001
-   `hiddenUnits` **[number][439]** default 100
-   `epochs` **[number][439]** default 20
-   `numClasses` **[number][439]** default 2
-   `batchSize` **[number][439]** default 0.4

## options

Type: [Object][437]

### Properties

-   `filterBoxesThreshold` **[number][439]** default 0.01
-   `IOUThreshold` **[number][439]** default 0.4
-   `classProbThreshold` **[number][439]** default 0.4

## options

Type: [Object][437]

### Properties

-   `filterBoxesThreshold` **[number][439]** Optional. default 0.01
-   `IOUThreshold` **[number][439]** Optional. default 0.4
-   `classProbThreshold` **[number][439]** Optional. default 0.4

## options

Type: [Object][437]

### Properties

-   `architecture` **[string][441]** default 'MobileNetV1',
-   `inputResolution` **[number][439]** default 257,
-   `imageScaleFactor` **[number][439]** default 0.3
-   `outputStride` **[number][439]** default 16
-   `flipHorizontal` **[boolean][440]** default false
-   `minConfidence` **[number][439]** default 0.5
-   `maxPoseDetections` **[number][439]** default 5
-   `scoreThreshold` **[number][439]** default 0.5
-   `nmsRadius` **[number][439]** default 20
-   `detectionType` **[String][441]** default single
-   `nmsRadius` **multiplier** default 0.75,
-   `quantBytes` **multiplier** default 2,

## options

Type: [Object][437]

### Properties

-   `seed` **[String][441]** 
-   `length` **[number][439]** 
-   `temperature` **[number][439]** 

## featureExtractor

Create a featureExtractor.

### Parameters

-   `model` **model** The model from which extract the learned features. Case-insensitive
-   `optionsOrCallback`  
-   `cb` **[function][438]** Optional.

## hasAnyTrainedClass

Boolean value that specifies if new data has been added to the model

Type: [boolean][440]

## isPredicting

Boolean value to check if the model is predicting.

Type: [boolean][440]

## usageType

String that specifies how is the Extractor being used. 
   Possible values are 'regressor' and 'classifier'

Type: [String][441]

## classification

Use the features of MobileNet as a classifier.

### Parameters

-   `video`  
-   `objOrCallback`   (optional, default `null`)
-   `callback` **[function][438]** Optional. A function to be called once 
       the video is ready. If no callback is provided, it will return a 
       promise that will be resolved once the video element has loaded.

## regression

Use the features of MobileNet as a regressor.

### Parameters

-   `video`  
-   `callback` **[function][438]** Optional. A function to be called once 
       the video is ready. If no callback is provided, it will return a 
       promise that will be resolved once the video element has loaded.

## addImage

Adds a new image element to  Mobilenet

### Parameters

-   `inputOrLabel`  
-   `labelOrCallback`  
-   `cb` **[function][438]** 

## train

Retrain the model with the provided images and labels using the 
   models original features as starting point.

### Parameters

-   `onProgress` **[function][438]** A function to be called to follow 
       the progress of the training.

## classify

Classifies an an image based on a new retrained model. 
   .classification() needs to be used with this.

### Parameters

-   `inputOrCallback`  
-   `cb` **[function][438]** 

## predict

Predicts a continues values based on a new retrained model. 
   .regression() needs to be used with this.

### Parameters

-   `inputOrCallback`  
-   `cb` **[function][438]** 

## constructor

Create Word2Vec model

### Parameters

-   `modelPath` **[String][441]** path to pre-trained word vector model in .json e.g data/wordvecs1000.json
-   `callback` **[function][438]** Optional. A callback function that is called once the model has loaded. If no callback is provided, it will return a promise 
       that will be resolved once the model has loaded.

## constructor

### Parameters

-   `video`  
-   `options`  
-   `callback`  

**Meta**

-   **deprecated**: Please use ObjectDetector class instead


## constructor

Create YOLO model. Works on video and images.

### Parameters

-   `video` **([HTMLVideoElement][442] \| [HTMLImageElement][443] \| [HTMLCanvasElement][444] | ImageData)** Optional. The video to be used for object detection and classification.
-   `options` **[Object][437]** Optional. A set of options.
-   `callback` **[function][438]** Optional. A callback function that is called once the model has loaded.

## detect

Detect objects that are in video, returns bounding box, label, and confidence scores

### Parameters

-   `inputOrCallback`  
-   `cb`  
-   `subject` **([HTMLVideoElement][442] \| [HTMLImageElement][443] \| [HTMLCanvasElement][444] | ImageData)** Subject of the detection.
-   `callback` **[function][438]** Optional. A callback function that is called once the model has loaded. If no callback is provided, it will return a promise
       that will be resolved once the prediction is done.

Returns **[ObjectDetectorPrediction][445]** 

## detectInternal

Detect objects that are in video, returns bounding box, label, and confidence scores

### Parameters

-   `imgToPredict`  
-   `subject` **([HTMLVideoElement][442] \| [HTMLImageElement][443] \| [HTMLCanvasElement][444] | ImageData)** Subject of the detection.

Returns **[ObjectDetectorPrediction][445]** 

## ObjectDetectorPrediction

Type: [Object][437]

### Properties

-   `x` **[number][439]** top left x coordinate of the prediction box in pixels.
-   `y` **[number][439]** top left y coordinate of the prediction box in pixels.
-   `width` **[number][439]** width of the prediction box in pixels.
-   `height` **[number][439]** height of the prediction box in pixels.
-   `label` **[string][441]** the label given.
-   `confidence` **[number][439]** the confidence score (0 to 1).
-   `normalized` **[ObjectDetectorPredictionNormalized][446]** a normalized object of the predicition

## ObjectDetectorPrediction

Type: [Object][437]

### Properties

-   `x` **[number][439]** top left x coordinate of the prediction box in pixels.
-   `y` **[number][439]** top left y coordinate of the prediction box in pixels.
-   `width` **[number][439]** width of the prediction box in pixels.
-   `height` **[number][439]** height of the prediction box in pixels.
-   `label` **[string][441]** the label given.
-   `confidence` **[number][439]** the confidence score (0 to 1).
-   `normalized` **[ObjectDetectorPredictionNormalized][446]** a normalized object of the predicition

## ObjectDetectorPredictionNormalized

Type: [Object][437]

### Properties

-   `x` **[number][439]** top left x coordinate of the prediction box (0 to 1).
-   `y` **[number][439]** top left y coordinate of the prediction box (0 to 1).
-   `width` **[number][439]** width of the prediction box (0 to 1).
-   `height` **[number][439]** height of the prediction box (0 to 1).

## ObjectDetectorPredictionNormalized

Type: [Object][437]

### Properties

-   `x` **[number][439]** top left x coordinate of the prediction box (0 to 1).
-   `y` **[number][439]** top left y coordinate of the prediction box (0 to 1).
-   `width` **[number][439]** width of the prediction box (0 to 1).
-   `height` **[number][439]** height of the prediction box (0 to 1).

## constructor

Create ObjectDetector model. Works on video and images.

### Parameters

-   `modelNameOrUrl` **[string][441]** The name or the URL of the model to use. Current model name options
       are: 'YOLO' and 'CocoSsd'.
-   `video`  
-   `options` **[Object][437]** Optional. A set of options.
-   `callback` **[function][438]** Optional. A callback function that is called once the model has loaded.

## constructor

Create CocoSsd model. Works on video and images.

### Parameters

-   `video`  
-   `options`  
-   `constructorCallback` **[function][438]** Optional. A callback function that is called once the model has loaded. If no callback is provided, it will return a promise
       that will be resolved once the model has loaded.

## loadModel

load model

## detectInternal

Detect objects that are in video, returns bounding box, label, and confidence scores

### Parameters

-   `imgToPredict`  
-   `subject` **([HTMLVideoElement][442] \| [HTMLImageElement][443] \| [HTMLCanvasElement][444] | ImageData)** Subject of the detection.

Returns **[ObjectDetectorPrediction][445]** 

## detect

Detect objects that are in video, returns bounding box, label, and confidence scores

### Parameters

-   `inputOrCallback`  
-   `cb`  
-   `subject` **([HTMLVideoElement][442] \| [HTMLImageElement][443] \| [HTMLCanvasElement][444] | ImageData)** Subject of the detection.
-   `callback` **[function][438]** Optional. A callback function that is called once the model has loaded. If no callback is provided, it will return a promise
       that will be resolved once the prediction is done.

Returns **[ObjectDetectorPrediction][445]** 

## constructor

Create a PoseNet model.

### Parameters

-   `video`  
-   `options` **[options][447]** Optional. An object describing a model accuracy and performance.
-   `detectionType` **[String][441]** Optional. A String value to run 'single' or 'multiple' estimation.
-   `callback` **[function][438]** Optional. A function to run once the model has been loaded. 
       If no callback is provided, it will return a promise that will be resolved once the 
       model has loaded.

## modelUrl

The type of detection. 'single' or 'multiple'

Type: [String][441]

## singlePose

Given an image or video, returns an array of objects containing pose estimations 
   using single or multi-pose detection.

### Parameters

-   `inputOr`  
-   `cb` **[function][438]** 

## multiPose

Given an image or video, returns an array of objects containing pose 
   estimations using single or multi-pose detection.

### Parameters

-   `inputOr`  
-   `cb` **[function][438]** 

## constructor

Create a new Style Transfer Instance。

### Parameters

-   `model` **model** The path to Style Transfer model.
-   `video`  
-   `callback` **funciton** Optional. A function to be called once the model is loaded. If no callback is provided, it will return a promise that will be resolved once the model has loaded.

## ready

Boolean value that specifies if the model has loaded.

Type: [boolean][440]

## transfer

### Parameters

-   `inputOrCallback`  
-   `cb`  
-   `callback` **funciton** Optional. A function to run once the model has made the transfer. If no callback is provided, it will return a promise that will be resolved once the model has made the transfer.

## constructor

Create a CharRNN.

### Parameters

-   `modelPath` **[String][441]** The path to the trained charRNN model.
-   `callback` **[function][438]** Optional. A callback to be called once 
       the model has loaded. If no callback is provided, it will return a 
       promise that will be resolved once the model has loaded.

## ready

Boolean value that specifies if the model has loaded.

Type: [boolean][440]

## model

The pre-trained charRNN model.

Type: model

## state

The vocabulary size (or total number of possible characters).

## reset

Reset the model state.

## generate

Generates content in a stateless manner, based on some initial text 
   (known as a "seed"). Returns a string.

### Parameters

-   `options` **[options][447]** An object specifying the input parameters of 
       seed, length and temperature. Default length is 20, temperature is 0.5 
       and seed is a random character from the model. The object should look like 
       this:
-   `callback` **[function][438]** Optional. A function to be called when the model 
       has generated content. If no callback is provided, it will return a promise 
       that will be resolved once the model has generated new content.

## predict

Predict the next character based on the model's current state.

### Parameters

-   `temp` **[number][439]** 
-   `callback` **[function][438]** Optional. A function to be called when the 
       model finished adding the seed. If no callback is provided, it will 
       return a promise that will be resolved once the prediction has been generated.

## feed

Feed a string of characters to the model state.

### Parameters

-   `inputSeed` **[String][441]** A string to feed the charRNN model state.
-   `callback` **[function][438]** Optional. A function to be called when 
       the model finished adding the seed. If no callback is provided, it 
       will return a promise that will be resolved once seed has been fed.

## constructor

Create a Pix2pix model.

### Parameters

-   `model` **model** The path for a valid model.
-   `callback` **[function][438]** Optional. A function to run once the model has been loaded. If no callback is provided, it will return a promise that will be resolved once the model has loaded.

## ready

Boolean to check if the model has loaded

Type: [boolean][440]

## transfer

Given an canvas element, applies image-to-image translation using the provided model. Returns an image.

### Parameters

-   `inputElement` **[HTMLCanvasElement][444]** 
-   `cb` **[function][438]** A function to run once the model has made the transfer. If no callback is provided, it will return a promise that will be resolved once the model has made the transfer.

## constructor

Create SketchRNN.

### Parameters

-   `model` **[String][441]** The name of the sketch model to be loaded.
       The names can be found in the models.js file
-   `callback` **[function][438]** Optional. A callback function that is called once the model has loaded. If no callback is provided, it will return a promise 
       that will be resolved once the model has loaded.
-   `large`   (optional, default `true`)

## constructor

Create UNET class.

### Parameters

-   `video` **([HTMLVideoElement][442] \| [HTMLImageElement][443])** The video or image to be used for segmentation.
-   `options` **[Object][437]** Optional. A set of options.
-   `callback` **[function][438]** Optional. A callback function that is called once the model has loaded. If no callback is provided, it will return a promise 
       that will be resolved once the model has loaded.

## constructor

Create a Conditional Variational Autoencoder (CVAE).

### Parameters

-   `modelPath` **[String][441]** Required. The url path to your model.
-   `callback` **[function][438]** Required. A function to run once the model has been loaded.

## ready

Boolean value that specifies if the model has loaded.

Type: [boolean][440]

## generate

Generate a random result.

### Parameters

-   `label` **[String][441]** A label of the feature your want to generate
-   `callback` **[function][438]** A function to handle the results of ".generate()". Likely a function to do something with the generated image data.

## constructor

Create an DCGAN.

### Parameters

-   `modelPath`  
-   `options`  
-   `callback`  
-   `modelName` **modelName** The name of the model to use.
-   `readyCb` **[function][438]** A callback to be called when the model is ready.

## loadModel

Load the model and set it to this.model

Returns **this** the dcgan.

## generate

Generates a new image

### Parameters

-   `callback` **[function][438]** a callback function handle the results of generate
-   `latentVector` **[object][437]** an array containing the latent vector; otherwise use random vector

Returns **[object][437]** a promise or the result of the callback function.

## compute

Computes what will become the image tensor

### Parameters

-   `latentDim` **[number][439]** the number of latent dimensions to pass through
-   `latentVector` **[object][437]** an array containing the latent vector; otherwise use random vector

Returns **[object][437]** a tensor

## generateInternal

Takes the tensor from compute() and returns an object of the generate image data

### Parameters

-   `latentVector` **[object][437]** an array containing the latent vector; otherwise use random vector

Returns **[object][437]** includes blob, raw, and tensor. if P5 exists, then a p5Image

## registerPreload

a list to store all functions to hook p5 preload

### Parameters

-   `obj`  
-   `object` **obj** or prototype to wrap with

Returns **any** obj

## OOV_CHAR

Initializes the Sentiment demo.

Type: [number][439]

## constructor

Create Sentiment model. Currently the supported model name is 'moviereviews'. ml5 may support different models in the future.

### Parameters

-   `modelName` **[String][441]** A string to the path of the JSON model.
-   `callback` **[function][438]** Optional. A callback function that is called once the model has loaded. If no callback is provided, it will return a promise that will be resolved once the model has loaded.

## ready

Boolean value that specifies if the model has loaded.

Type: [boolean][440]

## loadModel

Initializes the Sentiment demo.

### Parameters

-   `modelName`  

## model

The model being used.

Type: model

## predict

Scores the sentiment of given text with a value between 0 ("negative") and 1 ("positive").

### Parameters

-   `text` **[String][441]** string of text to predict.

Returns **{score: [Number][439]}** 

## constructor

Create BodyPix.

### Parameters

-   `video` **[HTMLVideoElement][442]** An HTMLVideoElement.
-   `options` **[object][437]** An object with options.
-   `callback` **[function][438]** A callback to be called when the model is ready.

## loadModel

Load the model and set it to this.model

Returns **this** the BodyPix model.

## p5Color2RGB

Returns an rgb array

### Parameters

-   `p5ColorObj`  
-   `a` **[Object][437]** p5.Color obj

Returns **[Array][448]** an [r,g,b] array

## convertToP5Image

Returns a p5Image

### Parameters

-   `tfBrowserPixelImage` **any** 
-   `segmentationWidth`  
-   `segmentationHeight`  

## bodyPartsSpec

Returns a bodyPartsSpec object

### Parameters

-   `colorOptions`  
-   `an` **[Array][448]** array of [r,g,b] colors

Returns **[object][437]** an object with the bodyParts by color and id

## segmentWithPartsInternal

Segments the image with partSegmentation, return result object

### Parameters

-   `imgToSegment`  
-   `segmentationOptions` **[object][437]** config params for the segmentation
       includes outputStride, segmentationThreshold
-   `imageToSegment` **([HTMLImageElement][443] \| [HTMLCanvasElement][444] \| [object][437] \| [function][438] \| [number][439])**    takes any of the following params

Returns **[Object][437]** a result object with image, raw, bodyParts

## segmentWithParts

Segments the image with partSegmentation

### Parameters

-   `optionsOrCallback` **([HTMLImageElement][443] \| [HTMLCanvasElement][444] \| [object][437] \| [function][438] \| [number][439])**    takes any of the following params
-   `configOrCallback` **[object][437]** config params for the segmentation
       includes palette, outputStride, segmentationThreshold
-   `cb` **[function][438]** a callback function that handles the results of the function.

Returns **[function][438]** a promise or the results of a given callback, cb.

## segmentInternal

Segments the image with personSegmentation, return result object

### Parameters

-   `imgToSegment`  
-   `segmentationOptions` **[object][437]** config params for the segmentation
       includes outputStride, segmentationThreshold
-   `imageToSegment` **([HTMLImageElement][443] \| [HTMLCanvasElement][444] \| [object][437] \| [function][438] \| [number][439])**    takes any of the following params

Returns **[Object][437]** a result object with maskBackground, maskPerson, raw

## segment

Segments the image with personSegmentation

### Parameters

-   `optionsOrCallback` **([HTMLImageElement][443] \| [HTMLCanvasElement][444] \| [object][437] \| [function][438] \| [number][439])**    takes any of the following params
-   `configOrCallback` **[object][437]** config params for the segmentation
       includes outputStride, segmentationThreshold
-   `cb` **[function][438]** a callback function that handles the results of the function.

Returns **[function][438]** a promise or the results of a given callback, cb.

## init

////////////////////////////////////////////////////////////
Initialization
////////////////////////////////////////////////////////////

### Parameters

-   `callback`  

## init

init

### Parameters

-   `callback` **any** 

## createLayersNoTraining

createLayersNoTraining

## copy

copy

## addData

////////////////////////////////////////////////////////////
Adding Data
////////////////////////////////////////////////////////////

### Parameters

-   `xInputs`  
-   `yInputs`  
-   `options`   (optional, default `null`)

## addData

addData

### Parameters

-   `xInputs` **([Array][448] \| [Object][437])** 
-   `yInputs` **([Array][448] \| [Object][437])** 
-   `options` **any**  (optional, default `null`)

## loadDataFromUrl

loadData

### Parameters

-   `options` **any** 
-   `callback` **any** 

## loadDataInternal

loadDataInternal

### Parameters

-   `options` **any** 

## createMetaData

////////////////////////////////////////////////////////////
Metadata prep
////////////////////////////////////////////////////////////

### Parameters

-   `dataRaw`  

## prepareForTraining

////////////////////////////////////////////////////////////
Data prep and handling
////////////////////////////////////////////////////////////

### Parameters

-   `_dataRaw`   (optional, default `null`)

## prepareForTraining

Prepare data for training by applying oneHot to raw

### Parameters

-   `_dataRaw`   (optional, default `null`)
-   `dataRaw` **any** 

## normalizeData

normalizeData

### Parameters

-   `_dataRaw` **any**  (optional, default `null`)
-   `_meta` **any** 

## normalizeInput

normalize the input value

### Parameters

-   `value` **any** 
-   `_key` **any** 
-   `_meta` **any** 

## searchAndFormat

search though the xInputs and format for adding to data.raws

### Parameters

-   `input` **any** 

## formatInputItem

Returns either the original input or a pixelArray\[]

### Parameters

-   `input` **any** 

## convertTrainingDataToTensors

convertTrainingDataToTensors

### Parameters

-   `_trainingData` **any**  (optional, default `null`)
-   `_meta` **any**  (optional, default `null`)

## formatInputsForPrediction

format the inputs for prediction
this means applying onehot or normalization
so that the user can use original data units rather
than having to normalize

### Parameters

-   `_input` **any** 
-   `meta` **any** 
-   `inputHeaders` **any** 

## formatInputsForPredictionAll

formatInputsForPredictionAll

### Parameters

-   `_input` **any** 
-   `meta` **any** 
-   `inputHeaders` **any** 

## isOneHotEncodedOrNormalized

check if the input needs to be onehot encoded or
normalized

### Parameters

-   `_input` **any** 
-   `_key`  
-   `_meta` **any** 

## train

////////////////////////////////////////////////////////////
Model prep
////////////////////////////////////////////////////////////

### Parameters

-   `optionsOrCallback`  
-   `optionsOrWhileTraining`  
-   `callback`  

## train

train

### Parameters

-   `optionsOrCallback` **any** 
-   `optionsOrWhileTraining` **any** 
-   `callback` **any** 

## trainInternal

train

### Parameters

-   `_options` **any** 
-   `whileTrainingCb`  
-   `finishedTrainingCb`  
-   `_cb` **any** 

## addLayer

addLayer

### Parameters

-   `options` **any** 

## createNetworkLayers

add custom layers in options

### Parameters

-   `layerJsonArray`  
-   `meta`  

## addDefaultLayers

addDefaultLayers

### Parameters

-   `task`  
-   `meta`  
-   `_task` **any** 

## compile

compile the model

### Parameters

-   `_modelOptions`   (optional, default `null`)
-   `_learningRate`   (optional, default `null`)
-   `_options` **any** 

## predictSync

////////////////////////////////////////////////////////////
Prediction / classification
////////////////////////////////////////////////////////////

### Parameters

-   `_input`  

## predictSync

synchronous predict

### Parameters

-   `_input` **any** 

## predict

predict

### Parameters

-   `_input` **any** 
-   `_cb` **any** 

## predictMultiple

predictMultiple

### Parameters

-   `_input` **any** 
-   `_cb` **any** 

## classifySync

synchronous classify

### Parameters

-   `_input` **any** 

## classify

classify

### Parameters

-   `_input` **any** 
-   `_cb` **any** 

## classifyMultiple

classifyMultiple

### Parameters

-   `_input` **any** 
-   `_cb` **any** 

## predictSyncInternal

synchronous predict internal

### Parameters

-   `_input` **any** 
-   `_cb` **any** 

## predictInternal

predict

### Parameters

-   `_input` **any** 
-   `_cb` **any** 

## classifySyncInternal

synchronous classify internal

### Parameters

-   `_input` **any** 
-   `_cb` **any** 

## classifyInternal

classify

### Parameters

-   `_input` **any** 
-   `_cb` **any** 

## saveData

////////////////////////////////////////////////////////////
Save / Load Data
////////////////////////////////////////////////////////////

### Parameters

-   `name`  

## saveData

save data

### Parameters

-   `name` **any** 

## loadData

load data

### Parameters

-   `filesOrPath` **any**  (optional, default `null`)
-   `callback` **any** 

## save

////////////////////////////////////////////////////////////
Save / Load Model
////////////////////////////////////////////////////////////

### Parameters

-   `nameOrCb`  
-   `cb`  

## save

saves the model, weights, and metadata

### Parameters

-   `nameOrCb` **any** 
-   `cb` **any** 

## load

load a model and metadata

### Parameters

-   `filesOrPath` **any**  (optional, default `null`)
-   `cb`  
-   `callback` **any** 

## dispose

dispose and release memory for a model

## mutate

////////////////////////////////////////////////////////////
New methods for Neuro Evolution
////////////////////////////////////////////////////////////

### Parameters

-   `rate`  
-   `mutateFunction`  

## mutate

mutate the weights of a model

### Parameters

-   `rate` **any** 
-   `mutateFunction` **any** 

## crossover

create a new neural network with crossover

### Parameters

-   `other` **any** 

## init

initialize with create model

## createModel

creates a sequential model
uses switch/case for potential future where different formats are supported

### Parameters

-   `_type` **any**  (optional, default `'sequential'`)

## addLayer

add layer to the model
if the model has 2 or more layers switch the isLayered flag

### Parameters

-   `_layerOptions` **any** 

## compile

Compile the model
if the model is compiled, set the isCompiled flag to true

### Parameters

-   `_modelOptions` **any** 

## setOptimizerFunction

Set the optimizer function given the learning rate
as a paramter

### Parameters

-   `learningRate` **any** 
-   `optimizer` **any** 

## train

Calls the trainInternal() and calls the callback when finished

### Parameters

-   `_options` **any** 
-   `_cb` **any** 

## trainInternal

Train the model

### Parameters

-   `_options` **any** 

## predictSync

returns the prediction as an array synchronously

### Parameters

-   `_inputs` **any** 

## predict

returns the prediction as an array

### Parameters

-   `_inputs` **any** 

## classify

classify is the same as .predict()

### Parameters

-   `_inputs` **any** 

## classifySync

classify is the same as .predict()

### Parameters

-   `_inputs` **any** 

## save

save the model

### Parameters

-   `nameOrCb` **any** 
-   `cb` **any** 

## load

loads the model and weights

### Parameters

-   `filesOrPath` **any**  (optional, default `null`)
-   `callback` **any** 

## dispose

dispose and release the memory for the model

## mutate

mutate the weights of a model

### Parameters

-   `rate` **any**  (optional, default `0.1`)
-   `mutateFunction` **any** 

## crossover

create a new neural network with crossover

### Parameters

-   `other` **any** 

## createMetadata

////////////////////////////////////////////////////////
Summarize Data
////////////////////////////////////////////////////////

### Parameters

-   `dataRaw`  
-   `inputShape`   (optional, default `null`)

## createMetadata

create the metadata from the data
this covers:
 1\. getting the datatype from the data
 2\. getting the min and max from the data
 3\. getting the oneHot encoded values
 4\. getting the inputShape and outputUnits from the data

### Parameters

-   `dataRaw` **any** 
-   `inputShape` **any**  (optional, default `null`)

## getDataStats

get stats about the data

### Parameters

-   `dataRaw` **any** 

## getInputMetaStats

getRawStats
get back the min and max of each label

### Parameters

-   `dataRaw` **any** 
-   `inputOrOutputMeta` **any** 
-   `xsOrYs` **any** 

## getDataUnits

get the data units, inputshape and output units

### Parameters

-   `dataRaw` **any** 
-   `_arrayShape`   (optional, default `null`)

## getInputMetaUnits

get input

### Parameters

-   `_dataRaw` **any** 
-   `_inputsMeta` **any** 

## getDTypesFromData

getDTypesFromData
gets the data types of the data we're using
important for handling oneHot

### Parameters

-   `_dataRaw`  

## addData

////////////////////////////////////////////////////////
Add Data
////////////////////////////////////////////////////////

### Parameters

-   `xInputObj`  
-   `yInputObj`  

## addData

Add Data

### Parameters

-   `xInputObj` **[object][437]** , {key: value}, key must be the name of the property value must be a String, Number, or Array
-   `yInputObj` **any** , {key: value}, key must be the name of the property value must be a String, Number, or Array

## convertRawToTensors

////////////////////////////////////////////////////////
Tensor handling
////////////////////////////////////////////////////////

### Parameters

-   `dataRaw`  

## convertRawToTensors

convertRawToTensors
converts array of {xs, ys} to tensors

### Parameters

-   `dataRaw`  
-   `_dataRaw` **any** 
-   `meta` **any** 

## normalizeDataRaw

////////////////////////////////////////////////////////
data normalization / unnormalization
////////////////////////////////////////////////////////

### Parameters

-   `dataRaw`  

## normalizeDataRaw

normalize the dataRaw input

### Parameters

-   `dataRaw` **any** 

## normalizeInputData

normalizeRaws

### Parameters

-   `dataRaw` **any** 
-   `inputOrOutputMeta` **any** 
-   `xsOrYs` **any** 

## normalizeArray

normalizeArray

### Parameters

-   `inputArray`  
-   `options`  
-   `_input` **any** 
-   `_options` **any** 

## unnormalizeArray

unNormalizeArray

### Parameters

-   `inputArray`  
-   `options`  
-   `_input` **any** 
-   `_options` **any** 

## applyOneHotEncodingsToDataRaw

applyOneHotEncodingsToDataRaw
does not set this.data.raws
but rather returns them

### Parameters

-   `dataRaw`  
-   `_dataRaw` **any** 
-   `_meta` **any** 

## getDataOneHot

getDataOneHot
creates onehot encodings for the input and outputs
and adds them to the meta info

### Parameters

-   `dataRaw` **any** 

## getInputMetaOneHot

getOneHotMeta

### Parameters

-   `_dataRaw` **any** 
-   `_inputsMeta` **any** 
-   `xsOrYs` **any** 

## createOneHotEncodings

Returns a legend mapping the
data values to oneHot encoded values

### Parameters

-   `_uniqueValuesArray`  

## loadDataFromUrl

////////////////////////////////////////////////
saving / loading data
////////////////////////////////////////////////

### Parameters

-   `dataUrl`  
-   `inputs`  
-   `outputs`  

## loadDataFromUrl

Loads data from a URL using the appropriate function

### Parameters

-   `dataUrl` **any** 
-   `inputs` **any** 
-   `outputs` **any** 

## loadJSON

loadJSON

### Parameters

-   `dataUrlOrJson`  
-   `inputLabels`  
-   `outputLabels`  
-   `_dataUrlOrJson` **any** 
-   `_inputLabelsArray` **any** 
-   `_outputLabelsArray` **any** 

## loadCSV

loadCSV

### Parameters

-   `dataUrl`  
-   `inputLabels`  
-   `outputLabels`  
-   `_dataUrl` **any** 
-   `_inputLabelsArray` **any** 
-   `_outputLabelsArray` **any** 

## loadBlob

loadBlob

### Parameters

-   `dataUrlOrJson`  
-   `inputLabels`  
-   `outputLabels`  
-   `_dataUrlOrJson` **any** 
-   `_inputLabelsArray` **any** 
-   `_outputLabelsArray` **any** 

## loadData

loadData from fileinput or path

### Parameters

-   `filesOrPath` **any**  (optional, default `null`)
-   `callback` **any** 

## saveData

saveData

### Parameters

-   `name` **any** 

## saveMeta

Saves metadata of the data

### Parameters

-   `nameOrCb` **any** 
-   `cb` **any** 

## loadMeta

load a model and metadata

### Parameters

-   `filesOrPath` **any**  (optional, default `null`)
-   `callback` **any** 

## formatRawData

// TODO: convert ys into strings, if the task is classification
// if (this.config.architecture.task === "classification" && typeof output.ys[prop] !== "string") {
//   output.ys[prop] += "";
// }
formatRawData
takes a json and set the this.data.raw

### Parameters

-   `json` **any** 
-   `inputLabels` **[Array][448]** 
-   `outputLabels` **[Array][448]** 

## csvToJSON

csvToJSON
Creates a csv from a string

### Parameters

-   `csv` **any** 

## findEntries

findEntries
recursively attempt to find the entries
or data array for the given json object

### Parameters

-   `_data` **any** 

## scatterplot

creates a scatterplot from 1 input variable and 1 output variable

### Parameters

-   `inputLabel` **any** 
-   `outputLabel` **any** 
-   `data` **any** 

## scatterplotAll

creates a scatterplot from all input variables and all output variables

### Parameters

-   `inputLabels` **any** 
-   `outputLabels` **any** 
-   `data` **any** 

## barchart

creates a barchart from 1 input label and 1 output label

### Parameters

-   `inputLabel` **any** 
-   `outputLabel` **any** 
-   `data` **any** 

## trainingVis

create a confusion matrix

### Parameters

-   `inputLabels` **any** 
-   `outputLabels` **any** 
-   `data` **any** 

## trainingVis

Visualize the training of the neural net

## normalizeValue

normalizeValue

### Parameters

-   `value` **any** 
-   `min` **any** 
-   `max` **any** 

## unnormalizeValue

unNormalizeValue

### Parameters

-   `value` **any** 
-   `min` **any** 
-   `max` **any** 

## getMin

getMin

### Parameters

-   `_array` **any** 

## getMax

getMax

### Parameters

-   `_array` **any** 

## isJsonOrString

checks whether or not a string is a json

### Parameters

-   `str` **any** 

## zipArrays

zipArrays

### Parameters

-   `arr1` **any** 
-   `arr2` **any** 

## createLabelsFromArrayValues

createLabelsFromArrayValues

### Parameters

-   `incoming` **any** 
-   `prefix` **any** 

## formatDataAsObject

takes an array and turns it into a json object 
where the labels are the keys and the array values
are the object values

### Parameters

-   `incoming` **any** 
-   `labels` **any** 

## getDataType

returns a datatype of the value as string

### Parameters

-   `val` **any** 

## constructor

Create FaceApi.

### Parameters

-   `video` **[HTMLVideoElement][442]** An HTMLVideoElement.
-   `options` **[object][437]** An object with options.
-   `callback` **[function][438]** A callback to be called when the model is ready.

## loadModel

Load the model and set it to this.model

Returns **this** the BodyPix model.

## detect

.detect() - classifies multiple features by default

### Parameters

-   `optionsOrCallback` **any** 
-   `configOrCallback` **any** 
-   `cb` **any** 

## detectInternal

Detects multiple internal function

### Parameters

-   `imgToClassify`  
-   `faceApiOptions` **[Object][437]** 

## detectSingle

.detecSinglet() - classifies a single feature with higher accuracy

### Parameters

-   `optionsOrCallback` **any** 
-   `configOrCallback` **any** 
-   `cb` **any** 

## detectSingleInternal

Detects only a single feature

### Parameters

-   `imgToClassify`  
-   `faceApiOptions` **[Object][437]** 

## checkUndefined

Check if the given \_param is undefined, otherwise return the \_default

### Parameters

-   `_param` **any** 
-   `_default` **any** 

## getModelPath

Checks if the given string is an absolute or relative path and returns 
     the path to the modelJson

### Parameters

-   `absoluteOrRelativeUrl` **[String][441]** 

## setReturnOptions

Sets the return options for .detect() or .detectSingle() in case any are given

### Parameters

-   `faceApiOptions` **[Object][437]** 

## resizeResults

Resize results to size of input image

### Parameters

-   `detections`  
-   `width`  
-   `height`  
-   `str` **any** 

## landmarkParts

get parts from landmarks

### Parameters

-   `result` **any** 

## readCsv

Read in a csv file from a path to its location.

### Parameters

-   `path` **[string][441]** 

## loadDataset

Load and flatten an array of arrays, an array of objects, or a string
  path to a csv.

### Parameters

-   `inputData`  

## constructor

Create a K-Means.

### Parameters

-   `dataset`  
-   `options` **[options][447]** An object describing a model's parameters:-   k: number of clusters
    -   maxIter: Max number of iterations to try before forcing convergence.
    -   threshold: Threshold for updated centriod distance before declaring convergence.
-   `callback` **[function][438]** Optional. A callback to be called once 
       the model has loaded. If no callback is provided, it will return a 
       promise that will be resolved once the model has loaded.

## load

Load dataset, find initial centroids, and run model.

### Parameters

-   `dataset`  

## fit

Run K-Means algorithm.

## getClosestCentroids

Find closest centroids to each observation and store as attribute.

## closestCentroid

Load and flatten an array of arrays, an array of objects, or a string
  path to a csv.

### Parameters

-   `dataTensor`  

## classify

Assing `value` to a cluster.

### Parameters

-   `value`  

## recenterCentroids

Recenter each centroid.

## getEuclidianDistance

Calculate the Euclidian distance between two tensors.

### Parameters

-   `tensor1` **tf.tensor** 
-   `tensor2` **tf.tensor** 

## constructor

Create a CartoonGan model.

### Parameters

-   `options`  
-   `callback` **[function][438]** Required. A function to run once the model has been loaded.
-   `modelIdentifier` **[String][441]** Required. The name of pre-inluded model or the url path to your model.

## generate

generate an img based on input Image.

### Parameters

-   `inputOrCallback`  
-   `cb`  
-   `src` **([HTMLImageElement][443] \| [HTMLCanvasElement][444])** the source img you want to transfer.
-   `callback` **[function][438]** 

## loadModel

load model

## predict

Encodes a string or array based on the USE

### Parameters

-   `textArray`  
-   `callback` **any** 
-   `textString` **any** 

## encode

Encodes a string based on the loaded tokenizer if the withTokenizer:true

### Parameters

-   `textString` **any** 
-   `callback` **any** 

## setP5Instance

Set p5 instance globally.

### Parameters

-   `p5Instance` **[Object][437]** 

## checkP5

This function will check if the p5 is in the environment
Either it is in the p5Instance mode OR it is in the window

Returns **[boolean][440]** if it is in p5

## getBlob

Convert a canvas to Blob

### Parameters

-   `inputCanvas` **[HTMLCanvasElement][444]** 

Returns **[Blob][449]** blob object

## loadAsync

Load image in async way.

### Parameters

-   `url` **[String][441]** 

## rawToBlob

convert raw bytes to blob object

### Parameters

-   `raws` **[Array][448]** 
-   `x` **[number][439]** 
-   `y` **[number][439]** 

Returns **[Blob][449]** 

## blobToP5Image

Conver Blob to P5.Image

### Parameters

-   `blob` **[Blob][449]** 
-   `p5Img` **[Object][437]** 

[1]: #constructor

[2]: #parameters

[3]: #model

[4]: #audiocontext

[5]: #stream

[6]: #results

[7]: #getpitch

[8]: #parameters-1

[9]: #centmapping

[10]: #constructor-1

[11]: #parameters-2

[12]: #loadmodel

[13]: #parameters-3

[14]: #classifyinternal

[15]: #parameters-4

[16]: #classify

[17]: #parameters-5

[18]: #predict

[19]: #parameters-6

[20]: #constructor-2

[21]: #parameters-7

[22]: #classify-1

[23]: #parameters-8

[24]: #constructor-3

[25]: #addexample

[26]: #parameters-9

[27]: #classify-2

[28]: #parameters-10

[29]: #clearlabel

[30]: #parameters-11

[31]: #getcountbylabel

[32]: #getcount

[33]: #getnumlabels

[34]: #save

[35]: #parameters-12

[36]: #load

[37]: #parameters-13

[38]: #options

[39]: #properties

[40]: #options-1

[41]: #properties-1

[42]: #options-2

[43]: #properties-2

[44]: #options-3

[45]: #properties-3

[46]: #options-4

[47]: #properties-4

[48]: #featureextractor

[49]: #parameters-14

[50]: #hasanytrainedclass

[51]: #ispredicting

[52]: #usagetype

[53]: #classification

[54]: #parameters-15

[55]: #regression

[56]: #parameters-16

[57]: #addimage

[58]: #parameters-17

[59]: #train

[60]: #parameters-18

[61]: #classify-3

[62]: #parameters-19

[63]: #predict-1

[64]: #parameters-20

[65]: #constructor-4

[66]: #parameters-21

[67]: #constructor-5

[68]: #parameters-22

[69]: #constructor-6

[70]: #parameters-23

[71]: #detect

[72]: #parameters-24

[73]: #detectinternal

[74]: #parameters-25

[75]: #objectdetectorprediction

[76]: #properties-5

[77]: #objectdetectorprediction-1

[78]: #properties-6

[79]: #objectdetectorpredictionnormalized

[80]: #properties-7

[81]: #objectdetectorpredictionnormalized-1

[82]: #properties-8

[83]: #constructor-7

[84]: #parameters-26

[85]: #constructor-8

[86]: #parameters-27

[87]: #loadmodel-1

[88]: #detectinternal-1

[89]: #parameters-28

[90]: #detect-1

[91]: #parameters-29

[92]: #constructor-9

[93]: #parameters-30

[94]: #modelurl

[95]: #singlepose

[96]: #parameters-31

[97]: #multipose

[98]: #parameters-32

[99]: #constructor-10

[100]: #parameters-33

[101]: #ready

[102]: #transfer

[103]: #parameters-34

[104]: #constructor-11

[105]: #parameters-35

[106]: #ready-1

[107]: #model-1

[108]: #state

[109]: #reset

[110]: #generate

[111]: #parameters-36

[112]: #predict-2

[113]: #parameters-37

[114]: #feed

[115]: #parameters-38

[116]: #constructor-12

[117]: #parameters-39

[118]: #ready-2

[119]: #transfer-1

[120]: #parameters-40

[121]: #constructor-13

[122]: #parameters-41

[123]: #constructor-14

[124]: #parameters-42

[125]: #constructor-15

[126]: #parameters-43

[127]: #ready-3

[128]: #generate-1

[129]: #parameters-44

[130]: #constructor-16

[131]: #parameters-45

[132]: #loadmodel-2

[133]: #generate-2

[134]: #parameters-46

[135]: #compute

[136]: #parameters-47

[137]: #generateinternal

[138]: #parameters-48

[139]: #registerpreload

[140]: #parameters-49

[141]: #oov_char

[142]: #constructor-17

[143]: #parameters-50

[144]: #ready-4

[145]: #loadmodel-3

[146]: #parameters-51

[147]: #model-2

[148]: #predict-3

[149]: #parameters-52

[150]: #constructor-18

[151]: #parameters-53

[152]: #loadmodel-4

[153]: #p5color2rgb

[154]: #parameters-54

[155]: #converttop5image

[156]: #parameters-55

[157]: #bodypartsspec

[158]: #parameters-56

[159]: #segmentwithpartsinternal

[160]: #parameters-57

[161]: #segmentwithparts

[162]: #parameters-58

[163]: #segmentinternal

[164]: #parameters-59

[165]: #segment

[166]: #parameters-60

[167]: #init

[168]: #parameters-61

[169]: #init-1

[170]: #parameters-62

[171]: #createlayersnotraining

[172]: #copy

[173]: #adddata

[174]: #parameters-63

[175]: #adddata-1

[176]: #parameters-64

[177]: #loaddatafromurl

[178]: #parameters-65

[179]: #loaddatainternal

[180]: #parameters-66

[181]: #createmetadata

[182]: #parameters-67

[183]: #preparefortraining

[184]: #parameters-68

[185]: #preparefortraining-1

[186]: #parameters-69

[187]: #normalizedata

[188]: #parameters-70

[189]: #normalizeinput

[190]: #parameters-71

[191]: #searchandformat

[192]: #parameters-72

[193]: #formatinputitem

[194]: #parameters-73

[195]: #converttrainingdatatotensors

[196]: #parameters-74

[197]: #formatinputsforprediction

[198]: #parameters-75

[199]: #formatinputsforpredictionall

[200]: #parameters-76

[201]: #isonehotencodedornormalized

[202]: #parameters-77

[203]: #train-1

[204]: #parameters-78

[205]: #train-2

[206]: #parameters-79

[207]: #traininternal

[208]: #parameters-80

[209]: #addlayer

[210]: #parameters-81

[211]: #createnetworklayers

[212]: #parameters-82

[213]: #adddefaultlayers

[214]: #parameters-83

[215]: #compile

[216]: #parameters-84

[217]: #predictsync

[218]: #parameters-85

[219]: #predictsync-1

[220]: #parameters-86

[221]: #predict-4

[222]: #parameters-87

[223]: #predictmultiple

[224]: #parameters-88

[225]: #classifysync

[226]: #parameters-89

[227]: #classify-4

[228]: #parameters-90

[229]: #classifymultiple

[230]: #parameters-91

[231]: #predictsyncinternal

[232]: #parameters-92

[233]: #predictinternal

[234]: #parameters-93

[235]: #classifysyncinternal

[236]: #parameters-94

[237]: #classifyinternal-1

[238]: #parameters-95

[239]: #savedata

[240]: #parameters-96

[241]: #savedata-1

[242]: #parameters-97

[243]: #loaddata

[244]: #parameters-98

[245]: #save-1

[246]: #parameters-99

[247]: #save-2

[248]: #parameters-100

[249]: #load-1

[250]: #parameters-101

[251]: #dispose

[252]: #mutate

[253]: #parameters-102

[254]: #mutate-1

[255]: #parameters-103

[256]: #crossover

[257]: #parameters-104

[258]: #init-2

[259]: #createmodel

[260]: #parameters-105

[261]: #addlayer-1

[262]: #parameters-106

[263]: #compile-1

[264]: #parameters-107

[265]: #setoptimizerfunction

[266]: #parameters-108

[267]: #train-3

[268]: #parameters-109

[269]: #traininternal-1

[270]: #parameters-110

[271]: #predictsync-2

[272]: #parameters-111

[273]: #predict-5

[274]: #parameters-112

[275]: #classify-5

[276]: #parameters-113

[277]: #classifysync-1

[278]: #parameters-114

[279]: #save-3

[280]: #parameters-115

[281]: #load-2

[282]: #parameters-116

[283]: #dispose-1

[284]: #mutate-2

[285]: #parameters-117

[286]: #crossover-1

[287]: #parameters-118

[288]: #createmetadata-1

[289]: #parameters-119

[290]: #createmetadata-2

[291]: #parameters-120

[292]: #getdatastats

[293]: #parameters-121

[294]: #getinputmetastats

[295]: #parameters-122

[296]: #getdataunits

[297]: #parameters-123

[298]: #getinputmetaunits

[299]: #parameters-124

[300]: #getdtypesfromdata

[301]: #parameters-125

[302]: #adddata-2

[303]: #parameters-126

[304]: #adddata-3

[305]: #parameters-127

[306]: #convertrawtotensors

[307]: #parameters-128

[308]: #convertrawtotensors-1

[309]: #parameters-129

[310]: #normalizedataraw

[311]: #parameters-130

[312]: #normalizedataraw-1

[313]: #parameters-131

[314]: #normalizeinputdata

[315]: #parameters-132

[316]: #normalizearray

[317]: #parameters-133

[318]: #unnormalizearray

[319]: #parameters-134

[320]: #applyonehotencodingstodataraw

[321]: #parameters-135

[322]: #getdataonehot

[323]: #parameters-136

[324]: #getinputmetaonehot

[325]: #parameters-137

[326]: #createonehotencodings

[327]: #parameters-138

[328]: #loaddatafromurl-1

[329]: #parameters-139

[330]: #loaddatafromurl-2

[331]: #parameters-140

[332]: #loadjson

[333]: #parameters-141

[334]: #loadcsv

[335]: #parameters-142

[336]: #loadblob

[337]: #parameters-143

[338]: #loaddata-1

[339]: #parameters-144

[340]: #savedata-2

[341]: #parameters-145

[342]: #savemeta

[343]: #parameters-146

[344]: #loadmeta

[345]: #parameters-147

[346]: #formatrawdata

[347]: #parameters-148

[348]: #csvtojson

[349]: #parameters-149

[350]: #findentries

[351]: #parameters-150

[352]: #scatterplot

[353]: #parameters-151

[354]: #scatterplotall

[355]: #parameters-152

[356]: #barchart

[357]: #parameters-153

[358]: #trainingvis

[359]: #parameters-154

[360]: #trainingvis-1

[361]: #normalizevalue

[362]: #parameters-155

[363]: #unnormalizevalue

[364]: #parameters-156

[365]: #getmin

[366]: #parameters-157

[367]: #getmax

[368]: #parameters-158

[369]: #isjsonorstring

[370]: #parameters-159

[371]: #ziparrays

[372]: #parameters-160

[373]: #createlabelsfromarrayvalues

[374]: #parameters-161

[375]: #formatdataasobject

[376]: #parameters-162

[377]: #getdatatype

[378]: #parameters-163

[379]: #constructor-19

[380]: #parameters-164

[381]: #loadmodel-5

[382]: #detect-2

[383]: #parameters-165

[384]: #detectinternal-2

[385]: #parameters-166

[386]: #detectsingle

[387]: #parameters-167

[388]: #detectsingleinternal

[389]: #parameters-168

[390]: #checkundefined

[391]: #parameters-169

[392]: #getmodelpath

[393]: #parameters-170

[394]: #setreturnoptions

[395]: #parameters-171

[396]: #resizeresults

[397]: #parameters-172

[398]: #landmarkparts

[399]: #parameters-173

[400]: #readcsv

[401]: #parameters-174

[402]: #loaddataset

[403]: #parameters-175

[404]: #constructor-20

[405]: #parameters-176

[406]: #load-3

[407]: #parameters-177

[408]: #fit

[409]: #getclosestcentroids

[410]: #closestcentroid

[411]: #parameters-178

[412]: #classify-6

[413]: #parameters-179

[414]: #recentercentroids

[415]: #geteuclidiandistance

[416]: #parameters-180

[417]: #constructor-21

[418]: #parameters-181

[419]: #generate-3

[420]: #parameters-182

[421]: #loadmodel-6

[422]: #predict-6

[423]: #parameters-183

[424]: #encode

[425]: #parameters-184

[426]: #setp5instance

[427]: #parameters-185

[428]: #checkp5

[429]: #getblob

[430]: #parameters-186

[431]: #loadasync

[432]: #parameters-187

[433]: #rawtoblob

[434]: #parameters-188

[435]: #blobtop5image

[436]: #parameters-189

[437]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Object

[438]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Statements/function

[439]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Number

[440]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Boolean

[441]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/String

[442]: https://developer.mozilla.org/docs/Web/API/HTMLVideoElement

[443]: https://developer.mozilla.org/docs/Web/API/HTMLImageElement

[444]: https://developer.mozilla.org/docs/Web/API/HTMLCanvasElement

[445]: #objectdetectorprediction

[446]: #objectdetectorpredictionnormalized

[447]: #options

[448]: https://developer.mozilla.org/docs/Web/JavaScript/Reference/Global_Objects/Array

[449]: https://developer.mozilla.org/docs/Web/API/Blob
